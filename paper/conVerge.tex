\documentclass[final]{clv2025}

\jvol{vv}
\jnum{nn}
\jyear{2025}
%There is no need for the authors to change the above.

% \dochead{An Example of Document Head} 
% Possible options: Long Paper, Short Paper, Survey, Survey Proposal, Position Paper, Last Words, Book Review, Dissertation Award, Lifetime Achievement Award, Squibs and Discussions, Featured Article

\pageonefooter{Action editor: \{action editor name\}. Submission received: DD Month YYYY; revised version received: DD Month YYYY; accepted for publication: DD Month YYYY.}
% To be filled when the paper is accepted. The editorial office will share the relevant information with the authors. Example: Action Editor: Wei Lu. Submission received: 10 February 2023; revised version received: 30 May 2023; accepted for publication: 15 June 2023.

\usepackage{amsmath}
\usepackage{booktabs}
\usepackage{xcolor}

\runningtitle{Running Article Title Here}
\runningauthor{Author's Surnames Here}

\begin{document}

\title{ConVerge: User-Controlled Conversational Context Graphs}

% \author{Vladimir Kovacevic$^{,1}$}
\author{Vladimir Kovacevic\thanks{}$^{,1}$}

\affilblock{
    \affil{School of Electrical Engineering, University of Belgrade\\\quad \email{vladimir.kovacevic@etf.bg.ac.rs}}
}


\maketitle

\begin{abstract}
Existing conversational AI systems model multi-turn interactions as linear sequences of messages, where context is provided implicitly through full or truncated conversation history. This representation limits users' ability to revise earlier queries, explore alternative reasoning paths, or explicitly control which parts of the conversation influence subsequent responses. This paper proposes ConVerge, a graph-based framework for representing conversational context that enables non-linear navigation and user-controlled context manipulation. Conversations are modeled as directed graphs with tree structure, where nodes represent conversational states containing context, responses, and artifacts, while edges capture user queries that trigger state transitions. This formulation supports key operations including node selection and branching, allowing users to navigate to any prior conversational state and explore multiple reasoning paths without modifying existing history. The approach is model-agnostic and compatible with existing language models, and tool-using agents by offering clear interface for easy integration.
\end{abstract}


\section{Problem Formulation}

A multi-turn human--AI interaction is considered as a process in which a user incrementally builds and revises conversational intent through a sequence of queries and responses. Existing conversational systems model this interaction as a linear sequence of turns, where the full or truncated history is implicitly provided as context to the language model. This representation limits the user's ability to revise earlier queries, explore alternative lines of reasoning, or explicitly control which parts of the conversation influence subsequent responses.

To address these limitations, a graph-based representation of conversational context is proposed that enables non-linear navigation, explicit branching, and selective inclusion of conversational history. This approach treats conversational state as a persistent, user-manipulable structure rather than a transient sequence of messages.

\section{Conversational Context Graph}

A conversation is modeled as a directed graph $G$, denoted as
\[
G = (V, E),
\]
where $V$ is the set of nodes representing conversational states, and $E \subseteq V \times V$ is the set of directed edges encoding contextual dependencies between nodes. The graph forms a tree structure: each node has at most one parent, with a single root node representing the initial conversational state.

Each node $v \in V$ corresponds to a conversational state and is defined as a tuple:
\[
v = (c, r, a, m),
\]
where:
\begin{itemize}
    \item $c$ is the context sent to the AI Agent, consisting of all previous queries optionally compressed or summarized,
    \item $r$ is the agent response generated using context $c$ (optional),
    \item $a$ denotes the associated contextual artifacts, such as retrieved documents, tool outputs, or summaries (optional),
    \item $m$ is the metadata, including timestamps and node identifiers.
\end{itemize}

Each directed edge $e = (v_i, v_j) \in E$ represents a conversational transition and is labeled with:
\[
e = (q),
\]
where $q$ is the user query consisting of text and optional artifacts that triggered the transition from state $v_i$ to state $v_j$.

Directed edges encode contextual dependency rather than strict temporal order. An edge $(v_i, v_j) \in E$ indicates that the conversational state represented by $v_j$ was derived using information contained in $v_i$.

This formulation allows multiple child nodes to originate from a single parent node, corresponding to conversational branching (e.g., alternative follow-up questions). Since nodes represent immutable conversational states and each node has exactly one parent, the graph is a tree and is acyclic by construction.

\section{Active Context Selection and Branching}


%     \item At any point during interaction, the user selects a subset of nodes\[S \subseteq V\] to define the active conversational context. This selection determines which parts of the graph influence the next model invocation. We define a context materialization function:
% \[
% \Phi(G, S) \rightarrow C_{\text{active}},
% \]
% where $C_{\text{active}}$ is a linearized representation of the selected nodes suitable for input to a language model. The function $\Phi$ may apply ordering, summarization, or truncation strategies but does not alter the underlying graph structure.
% Importantly, node selection is explicitly controlled by the user, enabling reuse of conversational history without modifying or deleting prior nodes.
The graph structure supports several core operations:

\begin{itemize}
    \item \textbf{Selecting}: The user explicitly chooses any existing node $v_i \in V$ to serve as the parent for the next conversational turn. This selection determines which conversational state provides the context for the subsequent AI Agent invocation. Unlike linear chat interfaces that implicitly use the most recent message, this operation allows users to navigate to any prior state and continue the conversation from that point without altering the existing graph structure.

    \item \textbf{Branching}: When a user submits a query $q$ from a selected node $v_i$, the system creates a new edge $(v_i, v_j)$ labeled with $q$ and a new child node $v_j$. The context $c_j$ in the new node is derived from the parent node's state (and potentially its ancestors), the query $q$ is sent to the AI Agent, and the resulting response $r_j$ along with any generated artifacts $a_j$ are stored in $v_j$. This mechanism enables users to explore alternative follow-up questions from the same conversational state, creating multiple reasoning branches without losing any prior work.

\end{itemize}

These operations allow users to explore multiple reasoning paths and revise earlier assumptions, which is not possible in strictly linear dialog models.

\section{Context Containment vs. Context Transmission}

A critical challenge in conversational AI systems is that agents typically do not expose their internal context construction to users \cite{openai2023gpt4,park2023generative}. Moreover, naively reconstructing context solely from previous queries and responses may be inaccurate, as it fails to capture intermediate reasoning steps, retrieved documents, tool outputs, and other artifacts that influence agent behavior \cite{wei2022chain,gao2023retrieval,mialon2023augmented}.

The ConVerge framework addresses this limitation by enabling AI agents to explicitly materialize and expose their context to users. Rather than requiring users to infer what information the agent is considering, the graph representation allows agents to populate the context field $c$ and artifacts field $a$ of each node, making the actual basis for each response transparent and directly inspectable by users. This explicit context exposure supports several benefits:

\begin{itemize}
    \item Users can verify what information influenced each response
    \item Context can be reviewed and potentially edited before reuse in branching scenarios making enforcing it to more accuratelly address current issue and also to optimze cost by lowering the number of spent query tokens
    \item The graph provides an audit trail of how context evolved throughout the conversation
\end{itemize}

A distinction is made between \emph{persistent conversational context} maintained within the graph nodes and \emph{transient model context} generated at invocation time. While the graph stores the historical context used for each turn, agents may apply additional transformations (summarization, truncation, reformatting) when constructing prompts for new queries. Protocols for agent communication and tool invocation operate downstream of this framework and remain orthogonal to the graph representation.

\section{Implementation Considerations}

The Conversational Context Graph is model-agnostic and can be layered on top of existing language models and agent architectures without requiring modifications to the underlying models themselves. The framework can be implemented as a middleware layer between the user interface and the language model API.

\paragraph{Data Storage} The tree structure can be efficiently stored using adjacency list representations or specialized tree data structures. Each node requires storage for context text, response text, artifacts (which may include embeddings, retrieved documents, or structured data), and metadata. Storage overhead grows linearly with conversation depth and branching factor. For long-running conversations, older subtrees can be archived or compressed without affecting the active conversation path.

\paragraph{User Interface} The framework necessitates UI elements for graph visualization and navigation. Users require the ability to: (1) view the conversation tree structure, (2) select any node as the active context, and (3) branch from any node. This can be implemented through tree visualizations (e.g., node-link diagrams), timeline interfaces with branching indicators, or hybrid approaches that show linear history with branch points highlighted.

\paragraph{Integration Example} Consider integrating ConVerge with an existing AI agent system. When a user submits a query, the system would: (1) identify the selected parent node $v_i$, (2) retrieve the context $c_i$ and artifacts $a_i$ from that node, (3) perform document retrieval based on the query and existing context, (4) construct the AI Agent prompt incorporating retrieved documents, (5) generate the response $r_j$, and (6) create a new node $v_j$ storing the updated context, response, and newly retrieved documents. Users could then select any previous node to explore alternative queries with different retrieved contexts, enabling comparison of different retrieval strategies or refinement of search terms without losing prior results.


\section{Related Work}

Traditional conversational AI systems maintain conversation history as linear sequences, with recent approaches employing sliding window mechanisms or hierarchical summarization to manage context length constraints \cite{zhao2023survey}. Some commercial chat interfaces offer limited branching capabilities through message editing and regeneration, but these typically overwrite history rather than preserving alternative paths.

Graph-based representations have been explored in task-oriented dialog systems for modeling dialog state and policy learning, but these focus on system-internal state management rather than user-facing context control. Version control metaphors have been applied to document editing and collaborative writing, yet their application to conversational AI remains unexplored. This work differs by providing explicit, user-controlled graph navigation with transparent context exposure, enabling users to treat conversational history as a manipulable artifact rather than an immutable sequence.

Recent work on multi-agent systems \cite{wu2023autogen} and iterative refinement \cite{madaan2023self} demonstrates the value of non-linear conversation patterns, but lacks formalization of the underlying graph structure and user control mechanisms that ConVerge provides. The framework complements these efforts by offering a principled representation for managing complex conversational flows.

\section{Conclusion}

This paper presents ConVerge, a graph-based framework for user-controlled conversational context management. By representing conversations as trees where nodes capture conversational states and edges encode user queries, the approach enables non-linear navigation, explicit branching, and transparent context exposure. The framework addresses fundamental limitations of linear conversation models, allowing users to explore alternative reasoning paths, revise earlier decisions, and inspect the contextual basis for agent responses.

ConVerge is model-agnostic and can be integrated with existing language models, retrieval-augmented generation systems, and agent architectures without modifications to the underlying models. The framework opens new possibilities for human-AI interaction, treating conversations as structures that can be explored and manipulated rather than ephemeral sequences. Future work includes empirical evaluation of user behavior with graph-based conversation interfaces and investigation of optimal visualization and navigation paradigms for complex conversational graphs.

\begin{acknowledgments}
The development and refinement of this paper was supported by Claude (Anthropic), an AI assistant that facilitated the iterative analysis and improvement of the wording.
\end{acknowledgments}

\bibliographystyle{compling}
\bibliography{references}

\end{document}
